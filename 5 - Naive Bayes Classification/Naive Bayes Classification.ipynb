{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" align=\"left\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png\" /></a>&nbsp;| [Emmanuel Rachelson](https://personnel.isae-supaero.fr/emmanuel-rachelson?lang=en) | <a href=\"https://supaerodatascience.github.io/machine-learning/\">https://supaerodatascience.github.io/machine-learning/</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:22pt; line-height:25pt; font-weight:bold; text-align:center;\">Bayesian models for Machine Learning<br>Naive Bayes Classification</div>\n",
    "\n",
    "One very common application of naive Bayes classifiers is document classification (e-mail spam filtering, sentiment analysis on social networks, technical documentation classification, customer appreciations, etc.). \n",
    "\n",
    "Naive Bayes classifiers for documents estimate the probability of a given document belonging to a certain class Y of documents, based on the document's contents Xi.\n",
    "\n",
    "\n",
    "Suppose we want to predict the probability that sample $x$ has label $y$. This is a probability estimation problem that can be written:\n",
    "$$\\mathbb{P}(Y=y|X=x)$$\n",
    "\n",
    "According to Bayes' theorem, we have:\n",
    "$$\\mathbb{P}(Y=y|X=x) =\\frac{\\mathbb{P}(X=x|Y=y)\\cdot\\mathbb{P}(Y=y)}{\\mathbb{P}(X=x)}$$\n",
    "$$\\textrm{posterior} = \\frac{\\textrm{likelihood}\\cdot\\textrm{prior}}{\\textrm{evidence}}$$\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "**Bayesian inference** is the problem of estimating this **posterior distribution**.<br>\n",
    "In plain words, it consists in estimating the probability of label $y$, given an input $x$, using previously seen data to estimate the **likelihood** of an $x$ input associated to label $y$ and the general **prior** probability of observing label $y$.\n",
    "</div>\n",
    "\n",
    "Note that Bayesian inference applies both to classification and regression.\n",
    "\n",
    "The goal of Bayesian inference is to estimate the label distribution for a given $x$ and use them to predict the correct label, so it is a *probabilistic approach to Machine Learning*.\n",
    "\n",
    "The Bayesian predictor (classifier or regressor) returns the label that maximizes the posterior probability distribution.\n",
    "\n",
    "In this (first) notebook on Bayesian modeling in ML, we will explore the method of Naive Bayes Classification.\n",
    "\n",
    "1. [The naive Bayes assumption](#sec1)\n",
    "2. [Naive Bayes classifiers in scikit-learn](#sec2)\n",
    "3. [Examples](#sec3)\n",
    "    1. [The \"spam or ham?\" example](#sec3-1)\n",
    "    2. [The NIST example](#sec3-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. <a id=\"sec1\"></a>The naive Bayes assumption\n",
    "\n",
    "Let's start with some illustrative data. We consider an artificial data set of 9 individuals. The first column in our data set is the sex ($S=0$ for male, 1 for female), the second is the height $H$ (in meters), the third is the weight $W$ (in kilos) and the last is the foot size $F$ (in centimeters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  1.82, 82.  , 30.  ],\n",
       "       [ 0.  ,  1.8 , 86.  , 28.  ],\n",
       "       [ 0.  ,  1.7 , 77.  , 30.  ],\n",
       "       [ 0.  ,  1.8 , 75.  , 25.  ],\n",
       "       [ 1.  ,  1.52, 45.  , 15.  ],\n",
       "       [ 1.  ,  1.65, 68.  , 20.  ],\n",
       "       [ 1.  ,  1.68, 59.  , 18.  ],\n",
       "       [ 1.  ,  1.75, 68.  , 23.  ],\n",
       "       [ 1.  ,  1.58, 49.  , 19.  ]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig_size=(10, 10)\n",
    "\n",
    "data = np.loadtxt(\"sex_classif.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions** :\n",
    "- Using matplotlib, bokeh, seaborn or plotly, plot one relevant figure on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Separate data by class for correct legend and coloring\n",
    "male = data[data[:,0] == 0]\n",
    "female = data[data[:,0] == 1]\n",
    "\n",
    "plt.scatter(male[:,1], male[:,2], color='blue', label='Homme')\n",
    "plt.scatter(female[:,1], female[:,2], color='yellow', label='Femme')\n",
    "plt.xlabel('Height')\n",
    "plt.ylabel('Weight')\n",
    "plt.title('Height vs Weight')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to answer the question: is $(H=1.81, W=59, F=21)$ male or female?\n",
    "\n",
    "Let's try to estimate $\\mathbb{P}(S=0|H=1.81, W=59, F=21)$.\n",
    "\n",
    "According to Bayes' theorem, the probability that a person that measures 1.81m, weights 59kgs and has a foot size of 21cm is male, is actually the likelihood of observing a person with such features among males, multiplied by the probability of observing males in the population, divided by the probability of observing an individual with these features.\n",
    "\n",
    "That's a long sentence. Let's write that mathematically:\n",
    "$$\\mathbb{P}(S=0|H=1.81, W=59, F=21) = \\frac{\\mathbb{P}(H=1.81, W=59, F=21 | S=0)\\cdot \\mathbb{P}(S=0)}{\\mathbb{P}(H=1.81, W=59, F=21)}$$\n",
    "\n",
    "Let's make that more readable and more general:\n",
    "$$\\mathbb{P}(S|H, W, F) = \\frac{\\mathbb{P}(H,W,F | S)\\cdot \\mathbb{P}(S)}{\\mathbb{P}(H,W,F)}$$\n",
    "\n",
    "Interestingly, since our goal is only to compare the probabilities for $S=0$ and $S=1$, the denominator in the last equation won't be relevant. So we are left with two terms to estimate, given the available data:\n",
    "- $\\mathbb{P}(S=0)$: the prior - the probability that any individual is $S=0$, regardless of his/her physical attributes;\n",
    "- $\\mathbb{P}(H=1.81, W=59, F=21 | S=0)$: the likelihood of meeting somebody with the specified features, given that his/her sex is $S=0$.\n",
    "\n",
    "The prior, in this case, is easy to estimate by comparing the frequencies of male and female individuals in the population.\n",
    "\\begin{gather*}\n",
    "\\mathbb{P}(S=0) = \\frac{4}{9}\\\\\n",
    "\\mathbb{P}(S=1) = \\frac{5}{9}\n",
    "\\end{gather*}\n",
    "Technically, the estimate above is obtained by [*maximum likelihood estimation*](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation).\n",
    "\n",
    "The likelihood, however, is a bit trickier. Can we directly estimate the **joint probability** of the 3 variables $(H,W,F)$?\n",
    "\n",
    "Theoretically, we can. We can assume that among male individuals, $(H,W,F)$ are distributed according to a multivariate Normal distribution, with mean $\\mu=(\\mu_H, \\mu_W, \\mu_F)$ and covariance matrix $\\Sigma$. The trick is then to estimate $\\mu$ and $\\Sigma$.\n",
    "\n",
    "As a matter of fact, estimating $\\mu$ and $\\Sigma$ without further hypothesis would require quite a lot of data, especially because $\\Sigma$ captures the **correlation** between $H$, $W$ and $F$.\n",
    "\n",
    "$\\Sigma$ is a $3\\times 3$ matrix, so it involves 9 parameters to estimate, and we unfortunately only have 9 data points.\n",
    "\n",
    "Let's rephrase this from another perspective. With some basic probabilities, we have:\n",
    "\\begin{align*}\n",
    "\\mathbb{P}(H,W,F | S) = &\\mathbb{P}(H | S)\\\\\n",
    "& \\cdot \\mathbb{P}(W | S, H) \\\\\n",
    "& \\cdot \\mathbb{P}(F | S, H, W)\n",
    "\\end{align*}\n",
    "\n",
    "Those three probabilities are univariate probabilities, much easier to estimate. However, the first one is a function of $S$ only, the second one depends on $S$ and $H$ and the third one depends on $S$, $H$ and $W$. To get an accurate estimate of the third one, we would need samples of the distribution of $F$ in enough points in the space of $(S,H,W)$ to cover it reasonably. This would require a number of data points that is exponential in the number of variables. That's what is called the **curse of dimensionality**, which makes this estimation problem difficult.\n",
    "\n",
    "Let's make this concrete. Suppose we discretize $H$, $W$ and $F$ in 10 bins each and suppose we require 100 samples to get a correct estimate of $\\mathbb{P}(F | S, H, W)$ for any given value of $(F, S, H, W)$. Then we need $100\\cdot 10^3\\cdot 2$ samples to correctly estimate this probability for all possible values of $(F, S, H, W)$. More generally, if we had $n$ continuous features rather than just three, we would require a number of data points that is exponential in $n$.\n",
    "\n",
    "To circumvent this problem, we are going to make a very **naive** assumption (hence the name of the method). We are going to assume that the weight, the height and the foot size are totally independent variables, that is the probability that a person be 1.85m is the same whatever his/her weight and foot size.\n",
    "\n",
    "Obviously, this hypothesis is very strong and clearly does not hold is most real-world cases. But we will assume it nonetheless. In this case, the likelihood estimation becomes:\n",
    "\\begin{align*}\n",
    "\\mathbb{P}(H,W,F | S) = &\\mathbb{P}(H | S)\\\\\n",
    "& \\cdot \\mathbb{P}(W | S) \\\\\n",
    "& \\cdot \\mathbb{P}(F | S)\n",
    "\\end{align*}\n",
    "\n",
    "Each of these probabilities now only depends on the label $S$ and is much easier to estimate from the data. This **conditional independence** assumption is called the **naive Bayes hypothesis**. It allow us to give a (very bad) estimate of $\\mathbb{P}(X | Y)$ and hence of $\\mathbb{P}(Y|X)$.\n",
    "\n",
    "$$\\mathbb{P}(S|H, W, F) = \\frac{\\mathbb{P}(H | S)\\cdot \\mathbb{P}(W | S) \\cdot \\mathbb{P}(F | S)\\cdot \\mathbb{P}(S)}{\\mathbb{P}(H, W, F)}$$\n",
    "\n",
    "Or, in our case:\n",
    "\n",
    "$$\\mathbb{P}(S=0|H=1.81, W=59, F=21) = \\frac{\\mathbb{P}(H=1.81 | S=0)\\cdot \\mathbb{P}(W=59 | S=0) \\cdot \\mathbb{P}(F=21 | S=0)\\cdot \\mathbb{P}(S=0)}{\\mathbb{P}(H=1.81, W=59, F=21)}$$\n",
    "\n",
    "The **naive Bayes classifier** is then the classifier that estimates all class probabilities and returns the one with maximum probability.\n",
    "\n",
    "$$f(H, W, F) = \\arg\\max_{s} \\mathbb{P}(S=s|H,W,F) = \\arg\\max_{s} \\mathbb{P}(H|S=s)\\cdot \\mathbb{P}(W|S=s) \\cdot \\mathbb{P}(F|S=s)\\cdot \\mathbb{P}(S=s)$$\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Exercice:**<br>\n",
    "Let's implement a naive Bayes classifier on the data above, just to practice. We will assume that the $\\mathbb{P}(X | S)$ distributions are Gaussians (for $X = H,W,$ or $F$). Compute the scores and probabilities for each sex, for $(H=1.81, W=59, F=21)$.<br>\n",
    "Hint: use the `np.mean` and `np.std` functions to estimate distribution parameters. Use `scipy.stats.norm.pdf` to compute the Gaussian probability density function in a given input.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score male    : 6.981284895980458e-10\n",
      "score female  : 0.0012161942837264688\n",
      "proba male    : 5.740267802562792e-07\n",
      "proba female  : 0.9999994259732197\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/code1.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n",
    "\n",
    "# Estimate distribution parameters for males\n",
    "dataM = data[data[:,0]==0]\n",
    "mu_HS0 = np.mean(dataM[:,1])\n",
    "std_HS0 = np.std(dataM[:,1])\n",
    "mu_WS0 = np.mean(dataM[:,2])\n",
    "std_WS0 = np.std(dataM[:,2])\n",
    "mu_FS0 = np.mean(dataM[:,3])\n",
    "std_FS0 = np.std(dataM[:,3])\n",
    "pS0 = dataM.shape[0]/data.shape[0]\n",
    "\n",
    "# Estimate distribution parameters for females\n",
    "dataF = data[data[:,0]==1]\n",
    "mu_HS1 = np.mean(dataF[:,1])\n",
    "std_HS1 = np.std(dataF[:,1])\n",
    "mu_WS1 = np.mean(dataF[:,2])\n",
    "std_WS1 = np.std(dataF[:,2])\n",
    "mu_FS1 = np.mean(dataF[:,3])\n",
    "std_FS1 = np.std(dataF[:,3])\n",
    "pS1 = dataF.shape[0]/data.shape[0]\n",
    "\n",
    "# score that (H=1.81,W=59,F=21) is male/female\n",
    "H=1.81\n",
    "W=59\n",
    "F=21\n",
    "from scipy.stats import norm\n",
    "score_M = pS0 * norm.pdf(H,mu_HS0,std_HS0) * norm.pdf(W,mu_WS0,std_WS0) * norm.pdf(F,mu_FS0,std_FS0)\n",
    "score_F = pS1 * norm.pdf(H,mu_HS1,std_HS1) * norm.pdf(W,mu_WS1,std_WS1) * norm.pdf(F,mu_FS1,std_FS1)\n",
    "print(\"score male    :\", score_M)\n",
    "print(\"score female  :\", score_F)\n",
    "print(\"proba male    :\", score_M/(score_M+score_F))\n",
    "print(\"proba female  :\", score_F/(score_M+score_F))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears we will always multiply together values that are smaller than one. The result will quickly become very small. It is a good habit to move to log-scale.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Exercice:**<br>\n",
    "Reuse your code above to compute log scores instead of scores.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log score male:     -21.08261794758859\n",
      "log score female:   -6.712028735399105\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/code2.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n",
    "\n",
    "log_score_M = np.log(pS0) + norm.logpdf(H,mu_HS0,std_HS0) + norm.logpdf(W,mu_WS0,std_WS0) + norm.logpdf(F,mu_FS0,std_FS0)\n",
    "log_score_F = np.log(pS1) + norm.logpdf(H,mu_HS1,std_HS1) + norm.logpdf(W,mu_WS1,std_WS1) + norm.logpdf(F,mu_FS1,std_FS1)\n",
    "print(\"log score male:    \", log_score_M)\n",
    "print(\"log score female:  \", log_score_F)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: $(H=1.81,W=59,F=21)$ is most probably female.\n",
    "\n",
    "Let's generalize.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "    \n",
    "Given $n$ features $X_i$ and classes $Y$, **naive Bayes classifiers** estimate (from data) the distributions $\\mathbb{P}(Y)$ and $\\mathbb{P}(X_i|Y)$. Then, using Bayes rule and the naive Bayes assumption, they predict the most probable estimated class:\n",
    "\\begin{align*}\n",
    "\\arg\\max_{y} \\mathbb{P}(Y=y|X=x) & = \\arg\\max_{y} \\frac{\\prod\\limits_{i=1}^n \\mathbb{P}(X_i=x_i|Y=y) \\mathbb{P}(Y=y)}{\\mathbb{P}(X=x)}\\\\\n",
    "& = \\arg\\max_{y} \\prod\\limits_{i=1}^n \\mathbb{P}(X_i=x_i|Y=y) \\mathbb{P}(Y=y)\\\\\n",
    "& = \\arg\\max_{y} \\sum\\limits_{i=1}^n \\log\\left(\\mathbb{P}(X_i=x_i|Y=y)\\right) + \\log\\left(\\mathbb{P}(Y=y)\\right)\n",
    "\\end{align*}\n",
    "</div>\n",
    "\n",
    "Note that although it is not compulsory to compute the denominator, it is quite straightforward since:\n",
    "\\begin{align*}\n",
    "\\mathbb{P}(X=x) &= \\sum\\limits_y \\mathbb{P}(X=x|Y=y)\\mathbb{P}(Y=y)\\\\\n",
    "&= \\sum\\limits_y \\prod\\limits_{i=1}^n \\mathbb{P}(X_i=x_i|Y=y) \\mathbb{P}(Y=y) \n",
    "\\end{align*}\n",
    "So it's the sum of the numerator's values for all $y$, so it's just a matter of normalizing the scores obtained.\n",
    "\n",
    "A really nice thing about naive Bayes classifiers is that it is an **online method**, since most univariate probability distributions can be updated incrementally, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"sec2\"></a> 2. Naive Bayes classifiers in scikit-learn\n",
    "\n",
    "Once again, scikit-learn has a [naive Bayes](http://scikit-learn.org/stable/modules/naive_bayes.html) implementation. It allows three kind of distributions for the $X_i|Y$ variables: Normal (continuous), Bernouilli or Multinomial (discrete).\n",
    "Let's directly use it on our toy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [1.]\n",
      "Probas:      [[5.73982396e-07 9.99999426e-01]]\n",
      "Log probas:  [[-1.43706671e+01 -5.73982561e-07]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "X = data[:,1:]\n",
    "y = data[:,0]\n",
    "gnb.fit(X,y)\n",
    "xtest = np.array([[1.81,59,21]])\n",
    "print(\"Prediction: \", gnb.predict(xtest))\n",
    "print(\"Probas:     \", gnb.predict_proba(xtest))\n",
    "print(\"Log probas: \",gnb.predict_log_proba(xtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"sec3\"></a> 3. Examples\n",
    "\n",
    "## <a id=\"sec3-1\"></a> 3.1 The \"spam or ham?\" example\n",
    "\n",
    "Let's scale up and apply naive Bayes classification on the ling-spam data. We will assume a multinomial distribution of word $i$ appearing in and email of class $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "from sys import path\n",
    "path.append('./machine-learning/2 - Text data preprocessing')\n",
    "import load_spam\n",
    "spam_data = load_spam.spam_data_loader()\n",
    "spam_data.load_data()\n",
    "print(\"data loaded\")\n",
    "\n",
    "Xtrain, ytrain, Xtest, ytest = spam_data.split(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Exercice:**\n",
    "Use scikit-learn to build a [multinomial naive Bayes classifier](http://scikit-learn.org/stable/modules/naive_bayes.html#multinomial-naive-bayes) on the data above. Estimate its generalization error.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9249720044792833\n",
      "******************** done!\n",
      "Average generalization score: 0.9323068309070548\n",
      "Standard deviation: 0.007330123382159312\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/code3.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "spam_nbc = MultinomialNB()\n",
    "spam_nbc.fit(Xtrain,ytrain)\n",
    "print(\"Score:\", spam_nbc.score(Xtest,ytest))\n",
    "\n",
    "# Compute cross-validation score\n",
    "nb_trials = 20\n",
    "score = []\n",
    "for i in range(nb_trials):\n",
    "    Xtrain, ytrain, Xtest, ytest = spam_data.shuffle_and_split(2000)\n",
    "    spam_nbc = MultinomialNB()\n",
    "    spam_nbc.fit(Xtrain,ytrain);\n",
    "    score += [spam_nbc.score(Xtest,ytest)]\n",
    "    print('*', end='')\n",
    "print(\" done!\")\n",
    "print(\"Average generalization score:\", np.mean(score))\n",
    "print(\"Standard deviation:\", np.std(score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've trained our model in the Tf-Idf data. Let's see how the model behaves on raw word counts.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Exercice:**\n",
    "Use scikit-learn to build a [multinomial naive Bayes classifier](http://scikit-learn.org/stable/modules/naive_bayes.html#multinomial-naive-bayes) on the raw word counts data below. Estimate its generalization error.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, ytrain, Xtest, ytest = spam_data.split(2000, feat='wordcount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.986562150055991\n",
      "******************** done!\n",
      "Average generalization score: 0.9886338185890258\n",
      "Standard deviation: 0.0031329977230767523\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/code4.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n",
    "\n",
    "spam_nbc = MultinomialNB()\n",
    "spam_nbc.fit(Xtrain,ytrain)\n",
    "print(\"Score:\", spam_nbc.score(Xtest,ytest))\n",
    "\n",
    "# Compute cross-validation score\n",
    "nb_trials = 20\n",
    "score = []\n",
    "for i in range(nb_trials):\n",
    "    Xtrain, ytrain, Xtest, ytest = spam_data.shuffle_and_split(2000, feat='wordcount')\n",
    "    spam_nbc = MultinomialNB()\n",
    "    spam_nbc.fit(Xtrain,ytrain);\n",
    "    score += [spam_nbc.score(Xtest,ytest)]\n",
    "    print('*', end='')\n",
    "print(\" done!\")\n",
    "print(\"Average generalization score:\", np.mean(score))\n",
    "print(\"Standard deviation:\", np.std(score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's identify which are the misclassified emails (and find the confusion matrix by the way)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain\n",
    "Xtrain, ytrain, Xtest, ytest = spam_data.split(2000, feat='wordcount')\n",
    "spam_nbc = MultinomialNB()\n",
    "spam_nbc.fit(Xtrain,ytrain);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified messages indices: [326, 328, 364, 450, 485, 511, 537, 619, 760, 776, 820, 892]\n"
     ]
    }
   ],
   "source": [
    "# Find misclassified examples\n",
    "ypredict = spam_nbc.predict(Xtest)\n",
    "misclass = np.not_equal(ypredict, ytest)\n",
    "Xmisclass = Xtest[misclass,:]\n",
    "ymisclass = ytest[misclass]\n",
    "misclass_indices = [i for i, j in enumerate(misclass) if j == True]\n",
    "print(\"Misclassified messages indices:\", misclass_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[737  12]\n",
      " [  0 144]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(ytest, ypredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [ True]\n",
      "email file: ../data/lingspam_public/bare/part2/6-1011msg1.txt\n",
      "email is a spam: False\n",
      "Subject: sum : word processors for linguists\n",
      "\n",
      "summary of question about numbered examples , etc . in word 2 for windows first of all i want to thank all those who showed me how to number examples in word and gave me other advice . secondly , i want to apologize for not mentioning that i was referring to windows programs , and not mac programs . most people who wrote figured that one out , probably from the version numbers . in what follows , my comments are in square brackets . this was the original question : > i am thinking of moving ( \" migrating \" ? ) from wordperfect 6 to ms word > 6 , which came bundled with my new computer , and would like to know if people > with similar experiences have anything of interest to say about such a move , > such as for example any good references to look into ( that are not too basic ; > the software did n't come with a reference manual , just the online manual ) . > > two specific questions : > > 1 ) numbered examples : wp can set up counters , which is how i dealt with > numbered examples . word does n't seem to have a similar > capability ? could that be possible ? how do people deal with automatic > numbering of examples in word ( as well as cross-references to examples ) ? > > 2 ) file manager : this is something where wp is better than word by a long > shot , but i understand there are add-ons for word out there . has anybody > heard of this ? > > 3 ) search software : while i ' m at it , i just got a message about a software > utility called powersearch , by commtech , which has powerful search mechanisms > and works in word or wordperfect ( there are two versions ) . has anyone had > any experience with this ? ( it is obtainable with ftp ) . windows vs . mac [ there are more than twice as much pcs out there than mac 's , but perhaps among linguists the percentages are more even . i ' m not ready to change though . i am quite happy with pcs thank you very much . ] you do n't say whether you ' re a mac or pc person , but the reviews of word 6 for mac were uniformly enormously negative : they actually ported woindows onto the mac ! since we mac users continually have to escape the really lousy windows imitations of things the mac does gracefully , we can't imaging why they did that ! the macuser review recommended nisuswritier as the word processor of choice now ( and if you are evern going to use alien scripts , there 's no substitute ) ; but you shluld also look at framemaker ( abvailable for lots of platforms , ioncluding windows ) ; it can number an idefinitely large number of different series , cross-refer between chapters that are separate files , etc . it only is n't woldscript - sensitive . ( version 4 . 0 . 4 was sort of , but was buggy , and in the just-released version 5 , they abancdoned it . ) wordperfect vs . word [ the advantage of wp for linguists is definitely the special characters it supports , though the special fonts that come with wp ( which are true type ) will work , i believe , with word , so word users can get a hold of these true type fonts from their wp user friends . ] i am in a similar situation : my new office computer came with microsoft office , which includes word . i toyed with the idea of switching from word perfect , but after a minimal amount of tinkering with word , i have about abandoned the idea . the main reason , for me , is that word perfect comes with a fairly extensive set of special characters , which i use a lot . they include several foreign alphabets , most of the ipa alphabet , characters for logical notation , and so forth . word , as far as i can tell , comes with hardly any of these . so i have about decided to erase office from my hard drive and install what i really use . numbered examples [ word can indeed number examples or anything at all . the terminology is a bit different though , which is why i was confused . in wp you set up counters , but in word you set up sequences . ] [ several people told me that they had gotten this to work , though they did n't all know how they did it . however , after they pointed me in the right direction , i was able to figure it out . ] you set up a counter by using the seq field ( look in your manual under fields ) . fields are somewhat like codes in wordperfect , they have links to things like counters ( chapter number , section , number ) or dates , file names , etc . one of the fields is seq . ( a ) chose : insert / field , click seq , which will give you a seq in the bottom window ; add \" ex / n \" to the right of the seq code in lower window , press return ( the ex is the name or identifier for the counter , the / n is to increase the number by 1 ) . the first time you do this a 1 will show up , the second a 2 , etc . ( you can set up more than one such counter / sequence by giving each sequence a diferent name an identifier ) ( there are many predefined sequences , e . g . { seq chapter } refers to chapter numbers . ) ( b ) you can create a macro , which then you can assign to a button or a key combination , which does : 1 ) choose a paragraph type you ' ve created which has the right margins , font size , etc . for your example paragraph ; and 2 ) right tab , ( , the stuff in ( a ) above , ) , left tab . ( c ) cross - referencing examples : very easy . first you have to create a bookmark for an example you want to cross-reference : a ) highlight the number created in ( a ) above ( along with the parentheses ) . b ) choose edit / bookmark , give the bookmark a name ( 40 characters ) , e . g . donkey _ sentence c ) when you want to refer to it , you type , e . g . , \" as we saw in example \" ; then you click insert / cross - reference , click bookmark , click the name of the bookmark , click insert . of course , many of these operations can be simplified with macros . there are many possibilities that i have n't mentioned . for instance , if you want to number the examples in ch . 3 in the format ( 3 . 1 ) , all you have to is before you insert the field for seq , you insert the field for the chapter . ] help on numbering in word 2 came from : numbering examples in dos : you are right , the automatic numbering of examples in word ( . 4 , . 5 & . 6 ) is inexistant which is a problem for linguists since we deal with a lot of examples in our text . if this can be of any interst for you i have found an excellent programm which allows me to do automatic numbering of examples as well as cross-references to examples in the text . the name of the program is renumber 1 . 2 and you can get it by writing to : jonathan mead ; 356 no . spaulding ave . ; los angele , ca ; usa 90036 or by e-mailing jonathan at : izzyt09 @ uclamvs i have been told that the fees for this programm are $ 15 . for student and $ 20 . for non student . [ i have used renumber in the past , and it works well . it is not as convenient as the features in word and wordperfect though . ] powerful searches if you are a mac user and are looking for super-sophisticated searching , try nisus which uses grep conventions and is the best going that i know of . regarding your 's earch ' question , there is a * lot * of stuff available out there , depending on the scope of your intended use . . . . if you ' re just going for personal use on 1 pc , you may want to look at eclipse find , not free , but only $ 99 , last time i looked . ( just my $ 0 . 02 ) . [ powersearch seems to be pretty nice . i downloaded it from simtel ( ftp oak . oakland . edu , cd simtel / win3 / winword ( or cd simtel / win3 / wpwin ) , and get the compressed binary file powersch . zip ( or searchwp . zip ) . unfortunatel this version has the powerful features locked , and to unlock them you have to send in $ 50 , which i have not done . the search possibilities seem pretty impressive . trees huge advantage if you would make use of it is that you can easily draw trees , using the integral drawing program ( from what people say , it sounds better than arboreal ) . i keep a little file of tree-parts . reference books [ i should say that the microsoft office professional cd-rom which came wih my computer does have all the manuals in it . af first , i was n't too excited about these electronic books , but now that i ' ve gotten used to the idea , it 's not so bad . ] books : i have borland 's running word 6 . it is fairly adequate . but it does not explain about styles and templates sufficiently , to my mind ( admittedly somewhat addled ) and it does not have enough information about long documents ( master documents ) . the index is useless , until you already know what you want to find out . the help system is extensive , though again it is sometimes hard to know what to ask it . depending on your learning style , you may be quite handicapped without a real manual , but happily there are commercial versions available at most bookstores \" prima visual learning guide for word 6 . 0 \" ( prima publishing , po box 1260bk rocklin , ca 95677 ) is an example . on the other hand , it is good to get used to the on-line help , because it 's always there . file managers what do you want to do ? delete files ? view files ? create directories ? windows file manager , while not the best option , offers much of this function , just a mouse click away . also , try word 's find file command ( under the file menu ) i was real happy when i figured out how to do this one : i knew you could look at a file in wp without opening it , but i was not sure how to do this in word : here 's how : from the file menu , choose find file . select the file whose contents you want to view . if you do n't see the file you are looking for , search for it : click on the search button , choose the drive and directory ( s ) you want to look in , make a wildcard filename ( like * . rev ) choose include subdirectories ( if you want to check your whole drive , etc ) , click on ok , and look at the list of files found . to preview the file , select preview in the view box ( still in the find file dialog box . then just click on the filename you want to look at , and you will see the first page on the screen . you can scroll through it to browse , you can delete , copy , open etc . by choosing the commands button . - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - jon aske home address : bates college 12 bardwell st . lewiston , maine 04240 , usa lewiston , maine 04240-6336 e-mail : jaske @ abacus . bates . edu - phone / fax : ( 207 ) 786-0589 - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = - = -\n",
      "\n",
      "Bag of words representation (340 words in dictionary):\n",
      "{'subject': np.int64(1), 'page': np.int64(1), 'information': np.int64(1), 'home': np.int64(1), 'list': np.int64(1), 'could': np.int64(2), 'know': np.int64(5), 'phone': np.int64(1), 'person': np.int64(1), 'show': np.int64(1), 'idea': np.int64(3), 'instance': np.int64(1), 'also': np.int64(2), 'several': np.int64(2), 'set': np.int64(6), 'deal': np.int64(2), 'available': np.int64(2), 'series': np.int64(1), 'first': np.int64(5), 'copy': np.int64(1), 'already': np.int64(1), 'may': np.int64(2), 'new': np.int64(2), 'view': np.int64(3), 'two': np.int64(2), 'see': np.int64(2), 'one': np.int64(4), 'field': np.int64(4), 'review': np.int64(1), 'many': np.int64(3), 'since': np.int64(2), 'original': np.int64(1), 'second': np.int64(1), 'guide': np.int64(1), 'anyone': np.int64(1), 'use': np.int64(6), 'say': np.int64(4), 'electronic': np.int64(1), 'would': np.int64(2), 'reference': np.int64(4), 'st': np.int64(1), 'time': np.int64(2), 'like': np.int64(4), 'last': np.int64(1), 'parenthesis': np.int64(1), 'non': np.int64(1), 'send': np.int64(1), 'name': np.int64(5), 'file': np.int64(15), 'mail': np.int64(1), 'get': np.int64(4), 'include': np.int64(2), 'along': np.int64(1), 'user': np.int64(2), 'even': np.int64(1), 'computer': np.int64(3), 'always': np.int64(1), 'better': np.int64(2), 'find': np.int64(5), 'people': np.int64(5), 'try': np.int64(2), 'increase': np.int64(1), 'office': np.int64(4), 'line': np.int64(1), 'want': np.int64(12), 'advantage': np.int64(2), 'whether': np.int64(1), 'large': np.int64(1), 'add': np.int64(2), 'believe': np.int64(1), 'whole': np.int64(1), 'perhaps': np.int64(1), 'give': np.int64(2), 'little': np.int64(1), 'hand': np.int64(1), 'check': np.int64(1), 'make': np.int64(2), 'ask': np.int64(1), 'address': np.int64(1), 'choose': np.int64(5), 'work': np.int64(4), 'experience': np.int64(1), 'number': np.int64(9), 'ca': np.int64(2), 'bad': np.int64(1), 'student': np.int64(2), 'understand': np.int64(1), 'possible': np.int64(1), 'word': np.int64(28), 'come': np.int64(4), 'scope': np.int64(1), 'real': np.int64(2), 'reason': np.int64(1), 'long': np.int64(2), 'ready': np.int64(1), 'going': np.int64(3), 'still': np.int64(1), 'open': np.int64(1), 'style': np.int64(1), 'format': np.int64(1), 'system': np.int64(1), 'without': np.int64(2), 'simplified': np.int64(1), 'tell': np.int64(1), 'depending': np.int64(2), 'content': np.int64(1), 'section': np.int64(1), 'something': np.int64(1), 'used': np.int64(3), 'good': np.int64(2), 'different': np.int64(2), 'hard': np.int64(2), 'writing': np.int64(1), 'font': np.int64(1), 'text': np.int64(2), 'size': np.int64(1), 'manual': np.int64(4), 'whose': np.int64(1), 'excellent': np.int64(1), 'easy': np.int64(1), 'program': np.int64(2), 'really': np.int64(2), 'code': np.int64(1), 'much': np.int64(3), 'searching': np.int64(1), 'main': np.int64(1), 'command': np.int64(1), 'free': np.int64(1), 'however': np.int64(1), 'course': np.int64(1), 'stuff': np.int64(2), 'summary': np.int64(1), 'sort': np.int64(1), 'example': np.int64(5), 'quite': np.int64(2), 'found': np.int64(2), 'lot': np.int64(4), 'anything': np.int64(2), 'away': np.int64(1), 'drive': np.int64(3), 'link': np.int64(1), 'well': np.int64(3), 'box': np.int64(3), 'interest': np.int64(1), 'type': np.int64(4), 'college': np.int64(1), 'option': np.int64(1), 'cross': np.int64(6), 'help': np.int64(3), 'special': np.int64(3), 'message': np.int64(1), 'thank': np.int64(2), 'function': np.int64(1), 'specific': np.int64(1), 'minimal': np.int64(1), 'question': np.int64(3), 'extensive': np.int64(2), 'probably': np.int64(1), 'sum': np.int64(1), 'press': np.int64(1), 'visual': np.int64(1), 'lower': np.int64(1), 'somewhat': np.int64(2), 'true': np.int64(2), 'indeed': np.int64(1), 'problem': np.int64(1), 'counter': np.int64(3), 'look': np.int64(8), 'choice': np.int64(1), 'keep': np.int64(1), 'looking': np.int64(2), 'negative': np.int64(1), 'opening': np.int64(1), 'foreign': np.int64(1), 'past': np.int64(1), 'learning': np.int64(2), 'rev': np.int64(1), 'direction': np.int64(1), 'sentence': np.int64(1), 'pointed': np.int64(1), 'left': np.int64(1), 'explain': np.int64(1), 'came': np.int64(4), 'chapter': np.int64(4), 'able': np.int64(1), 'sure': np.int64(1), 'wrote': np.int64(1), 'alphabet': np.int64(1), 'version': np.int64(4), 'shot': np.int64(1), 'change': np.int64(1), 'powerful': np.int64(3), 'combination': np.int64(1), 'basic': np.int64(1), 'amount': np.int64(1), 'regarding': np.int64(1), 'among': np.int64(1), 'index': np.int64(1), 'gave': np.int64(1), 'best': np.int64(2), 'actually': np.int64(1), 'alien': np.int64(1), 'sequence': np.int64(2), 'automatic': np.int64(3), 'edit': np.int64(1), 'done': np.int64(1), 'square': np.int64(1), 'separate': np.int64(1), 'far': np.int64(1), 'easily': np.int64(1), 'sensitive': np.int64(1), 'search': np.int64(5), 'key': np.int64(1), 'tree': np.int64(1), 'create': np.int64(3), 'right': np.int64(5), 'told': np.int64(2), 'mind': np.int64(1), 'got': np.int64(1), 'excited': np.int64(1), 'knew': np.int64(1), 'pretty': np.int64(2), 'saw': np.int64(1), 'button': np.int64(3), 'moving': np.int64(1), 'mouse': np.int64(1), 'happy': np.int64(2), 'huge': np.int64(1), 'super': np.int64(1), 'giving': np.int64(1), 'bottom': np.int64(1), 'continually': np.int64(1), 'select': np.int64(2), 'zip': np.int64(2), 'enough': np.int64(1), 'menu': np.int64(2), 'commercial': np.int64(1), 'perfect': np.int64(2), 'onto': np.int64(1), 'terminology': np.int64(1), 'hold': np.int64(1), 'do': np.int64(1), 'directory': np.int64(1), 'adequate': np.int64(1), 'twice': np.int64(1), 'decided': np.int64(1), 'running': np.int64(1), 'po': np.int64(1), 'seem': np.int64(2), 'figured': np.int64(2), 'personal': np.int64(1), 'move': np.int64(1), 'bit': np.int64(1), 'though': np.int64(6), 'delete': np.int64(2), 'figure': np.int64(1), 'definitely': np.int64(1), 'return': np.int64(1), 'sometimes': np.int64(1), 'refer': np.int64(2), 'useless': np.int64(1), 'intended': np.int64(1), 'ave': np.int64(1), 'situation': np.int64(1), 'professional': np.int64(1), 'preview': np.int64(2), 'insert': np.int64(5), 'window': np.int64(2), 'nice': np.int64(1), 'ex': np.int64(2), 'mac': np.int64(9), 'logical': np.int64(1), 'forth': np.int64(1), 'draw': np.int64(1), 'chose': np.int64(1), 'click': np.int64(9), 'arboreal': np.int64(1), 'drawing': np.int64(1), 'fairly': np.int64(2), 'substitute': np.int64(1), 'master': np.int64(1), 'confused': np.int64(1), 'similar': np.int64(3), 'sophisticated': np.int64(1), 'happily': np.int64(1), 'capability': np.int64(1), 'advice': np.int64(1), 'convenient': np.int64(1), 'highlight': np.int64(1), 'macro': np.int64(1), 'processor': np.int64(1), 'install': np.int64(1), 'ported': np.int64(1), 'hardly': np.int64(1), 'handicapped': np.int64(1), 'anybody': np.int64(1), 'secondly': np.int64(1), 'impressive': np.int64(1), 'thinking': np.int64(1), 'sufficiently': np.int64(1), 'paragraph': np.int64(2), 'screen': np.int64(1), 'assign': np.int64(1), 'tab': np.int64(2), 'admittedly': np.int64(1), 'switching': np.int64(1), 'nisus': np.int64(1), 'compressed': np.int64(1), 'apologize': np.int64(1), 'dealt': np.int64(1), 'choosing': np.int64(1), 'gotten': np.int64(2), 'manager': np.int64(2), 'escape': np.int64(1), 'binary': np.int64(1), 'integral': np.int64(1), 'notation': np.int64(1), 'browse': np.int64(1), 'donkey': np.int64(1), 'utility': np.int64(1), 'locked': np.int64(1), 'obtainable': np.int64(1), 'erase': np.int64(1), 'uniformly': np.int64(1), 'enormously': np.int64(1), 'abandoned': np.int64(1), 'scroll': np.int64(1), 'unlock': np.int64(1), 'oak': np.int64(1), 'ons': np.int64(1), 'bookmark': np.int64(5), 'prima': np.int64(2), 'identifier': np.int64(2), 'lousy': np.int64(1), 'gracefully': np.int64(1), 'buggy': np.int64(1), 'renumber': np.int64(2), 'mead': np.int64(1), 'eclipse': np.int64(1), 'abacus': np.int64(1)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.13395695, 0.86604305]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check some misclassified mails\n",
    "index = misclass_indices[1]+2000\n",
    "print(\"Prediction:\", spam_nbc.predict(spam_data.word_count[index,:]))\n",
    "spam_data.print_email(index)\n",
    "spam_nbc.predict_proba(spam_data.tfidf[index,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions** :\n",
    "- What are the next steps to improve the results ? To create the moderation system ?\n",
    "- What questions should you ask to the tech company, before working on their data ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"sec3-2\"></a> 3.2 The NIST example\n",
    "\n",
    "We will assume Gaussian distributions for the NIST example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797, 8, 8)\n",
      "(1797,)\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "print(digits.data.shape)\n",
    "print(digits.images.shape)\n",
    "print(digits.target.shape)\n",
    "print(digits.target_names)\n",
    "\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "Xtrain,Xtest = np.split(X,[1000])\n",
    "ytrain,ytest = np.split(y,[1000])\n",
    "#Xtrain = X[:1000,:]\n",
    "#ytrain = y[:1000]\n",
    "#Xtest = X[1000:,:]\n",
    "#ytest = y[1000:]\n",
    "\n",
    "#print(digits.DESCR)\n",
    "\n",
    "#plt.gray();\n",
    "#plt.matshow(digits.images[0]);\n",
    "#plt.show();\n",
    "#plt.matshow(digits.images[15]);\n",
    "#plt.show();\n",
    "#plt.matshow(digits.images[42]);\n",
    "#plt.show();\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def shuffle_and_split(X,y,n):\n",
    "    X0,y0 = shuffle(X,y)\n",
    "    Xtrain,Xtest = np.split(X0,[n])\n",
    "    ytrain,ytest = np.split(y0,[n])\n",
    "    return Xtrain, ytrain, Xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 64)\n",
      "(1000,)\n",
      "Generalization error: 0.1342534504391468\n",
      "Generalization score: 0.8657465495608532\n",
      "Confusion matrix:\n",
      "[[72  0  0  0  1  0  0  1  0  0]\n",
      " [ 0 65  2  0  0  0  0  1  6  2]\n",
      " [ 0  2 78  0  1  0  0  0  8  0]\n",
      " [ 0  1  2 69  0  3  0  3  6  0]\n",
      " [ 0  1  0  0 67  0  0  5  0  0]\n",
      " [ 0  2  0  1  1 78  0  1  2  0]\n",
      " [ 0  0  0  0  1  2 84  0  0  0]\n",
      " [ 0  0  0  0  1  0  0 68  0  0]\n",
      " [ 0  8  2  0  0  4  0  5 59  0]\n",
      " [ 0  3  1  8  1  3  0  8  8 50]]\n"
     ]
    }
   ],
   "source": [
    "Xtrain, ytrain, Xtest, ytest  = shuffle_and_split(X,y,1000)\n",
    "\n",
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "digits_nbc = GaussianNB()\n",
    "digits_nbc.fit(Xtrain,ytrain)\n",
    "prediction = digits_nbc.predict(Xtest)\n",
    "#print(\"Training error:\", np.sum(np.not_equal(prediction,ytest))/len(ytest))\n",
    "print(\"Generalization error:\", np.sum(np.not_equal(prediction,ytest))/len(ytest) )\n",
    "print(\"Generalization score:\", digits_nbc.score(Xtest,ytest))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(ytest, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** done!\n",
      "Average generalization score: 0.8361982434127979\n",
      "Standard deviation: 0.01834392223182867\n"
     ]
    }
   ],
   "source": [
    "# Compute cross-validation score\n",
    "nb_trials = 20\n",
    "score = []\n",
    "for i in range(nb_trials):\n",
    "    Xtrain, ytrain, Xtest, ytest = shuffle_and_split(X,y,1000)\n",
    "    digits_nbc = GaussianNB()\n",
    "    digits_nbc.fit(Xtrain,ytrain)\n",
    "    score += [digits_nbc.score(Xtest,ytest)]\n",
    "    print('*',end='')\n",
    "print(\" done!\")\n",
    "    \n",
    "print(\"Average generalization score:\", np.mean(score))\n",
    "print(\"Standard deviation:\", np.std(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes classifiers reach their limits on data with high correlations between features (like images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_sdd_py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": false,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
